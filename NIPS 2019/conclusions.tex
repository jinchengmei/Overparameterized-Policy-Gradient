\section{Conclusions}
\label{sec:conclusions}

In this paper, we provide finite time regret analysis of basic policy gradient method under the stochastic bandit setting, where the policy is represented by neural network function approximations. The main result is $O\left( T^{\frac{2}{3} } \left(\log{T}\right)^{\frac{1}{3}}\right)$. The results can be generalized to many state dependent bandit settings, episodic MDPs, and can be combined with multi-layered neural network function approximations. Our findings are at the starting point of understanding more perspectives and providing theoretical supports for deep reinforcement learning.
