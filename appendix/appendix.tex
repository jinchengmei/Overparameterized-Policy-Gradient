\documentclass[10pt]{article}
\usepackage[usenames]{color} %used for font color
\usepackage{amssymb} %maths
\usepackage{amsmath} %maths
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{subfigure}
\usepackage{algorithm,algorithmic}
\usepackage[utf8]{inputenc} %useful to type directly diacritic charactesrs
\usepackage[capitalize]{cleveref}
\usepackage[top=1.0in,bottom=1.0in,left=1.0in,right=1.0in]{geometry}

\crefname{prop}{Proposition}{Propositions}
\crefname{thm}{Theorem}{Theorems}
\crefname{lem}{Lemma}{Lemmas}
\crefname{algorithm}{Algorithm}{Algorithms}

\crefname{definition}{Definition}{Definitions}

\def\rva{{\mathbf{a}}}
\def\rvo{{\mathbf{o}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvu{{\mathbf{u}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvg{{\mathbf{g}}}
\def\rvo{{\mathbf{o}}}
\def\rvone{{\mathbf{1}}}
\def\rvzero{{\mathbf{0}}}
\def\rvhat{{\hat{\mathbf{r}}}}

\def\rvp{{\mathbf{p}}}

\def\pr{{\text{Pr}}}
\def\r{{\text{R}}}

\def\regret{{\text{Regret}}}

\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{defi}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{remk}{Remark}


\def\rvpi{{\boldsymbol{\pi}}}

\def\rmA{{\mathbf{A}}}
\def\rmD{{\mathbf{D}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}

\def\sE{{\mathbb{E}}}
\def\sR{{\mathbb{R}}}
\def\sI{{\mathbb{I}}}

\def\gH{{\mathcal{H}}}
\def\gN{{\mathcal{N}}}
\def\gE{{\mathcal{E}}}
\def\gU{{\mathcal{U}}}


\title{Appendix of ``On Optimal Stochastic Bandit Algorithms and Provable Policy Gradient Methods with Neural Networks''}
\author{}
\date{}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\probability}{Pr}
\DeclareMathOperator*{\expectation}{\sE}
\DeclareMathOperator*{\trace}{Tr}


\begin{document}

\maketitle

\appendix

\section{Proofs}

\begin{lem}
    Let $\rvo \in \sR^h$ be any logit vector, and $\rvpi(\rvo)$ be the softmax policy of $\rvo$ at state $\rvs$. Denote $\gH\left( \rvpi \left(\rvo \right) \right) \triangleq \Delta \left( \rvpi \left(\rvo \right) \right) - \rvpi \left(\rvo \right) \rvpi \left(\rvo \right)^\top$, where $\Delta \left( \rvpi \left(\rvo \right) \right) \in \sR^{h \times h}$ is a matrix with $\rvpi \left(\rvo \right)$ as its diagonal. $\forall \rvr \in \left[ 0, 1\right]^h$,
\begin{equation*}
    \left\| \frac{d \gH\left( \rvpi \left(\rvo \right) \right) \rvr}{d \rvo } \right\|_2 \le 2,
\end{equation*}
where $\left\| \cdot \right\|_2$ is the spectral norm of a matrix.
\end{lem}
\begin{proof}
    Denote $\rmH \triangleq \frac{d \gH\left( \rvpi \left(\rvo \right) \right) \rvr}{d \rvo } \in \sR^{h \times h}$. $\forall s, t \in [h]$,
\begin{equation*}
\begin{split}
    H_{s, t} &= \frac{d \pi_{s} \left( r_{s} - \rvpi^\top \rvr \right) }{d o_{t}} \\
    &= \frac{d \pi_{s} }{d o_{t}} \left( r_{s} - \rvpi^\top \rvr \right) + \pi_{s} \frac{d \left( r_{s} - \rvpi^\top \rvr \right) }{d o_{t}} \\
    &=\left ( \sI\left\{ s = t\right\} \pi_{t} -  \pi_{s } \pi_{t} \right) \left( r_{s} - \rvpi^\top \rvr \right) - \pi_{s} \left( \pi_{t} r_{t} - \pi_{t} \rvpi^\top \rvr \right).
\end{split}
\end{equation*}
For any vector $\rvx \in \sR^h$, 
\begin{equation*}
\begin{split}
    \rvx^\top \rmH \rvx &= \sum\limits_{s=1}^{h}{ \sum\limits_{t=1}^{h}{ H_{s,t} x_s x_t} } \\
    &= \expectation\limits_{\rvpi}\left[ \rvr \cdot \rvx \cdot \rvx \right] - \expectation\limits_{\rvpi}\left[ \rvr \right] \cdot \expectation\limits_{\rvpi}\left[ \rvx \cdot \rvx \right] - \expectation\limits_{\rvpi}\left[ \rvr \cdot \rvx \right] \cdot \expectation\limits_{\rvpi}\left[ \rvx \right] + \expectation\limits_{\rvpi}\left[ \rvr \right] \cdot \left( \expectation\limits_{\rvpi}\left[ \rvx \right] \right)^2  - \expectation\limits_{\rvpi}\left[ \rvr \cdot \rvx \right] \cdot \expectation\limits_{\rvpi}\left[ \rvx \right] + \expectation\limits_{\rvpi}\left[ \rvr \right] \cdot \left( \expectation\limits_{\rvpi}\left[ \rvx \right] \right)^2 \\
    &\le \expectation\limits_{\rvpi}\left[ \rvr \cdot \rvx \cdot \rvx \right] - \expectation\limits_{\rvpi}\left[ \rvr \cdot \rvx \right] \cdot \expectation\limits_{\rvpi}\left[ \rvx \right] - \expectation\limits_{\rvpi}\left[ \rvr \cdot \rvx \right] \cdot \expectation\limits_{\rvpi}\left[ \rvx \right] + \expectation\limits_{\rvpi}\left[ \rvr \right] \cdot \left( \expectation\limits_{\rvpi}\left[ \rvx \right] \right)^2 \\
    &\le \left\| \rvpi \right\|_2 \cdot \left\| \rvr \cdot \rvx \cdot \rvx \right\|_2 + 2 \cdot \left\| \rvpi \right\|_2 \cdot \left\| \rvr \cdot \rvx \right\|_2 \cdot \left\| \rvpi \right\|_2 \cdot \left\| \rvx \right\|_2 + \left\| \rvpi \right\|_2^2 \cdot \left\| \rvr \cdot \rvx \right\|_2^2 \\
    &\le \left\| \rvr \cdot \rvx \cdot \rvx \right\|_2 + 2 \cdot \left\| \rvr \cdot \rvx \right\|_2 \cdot \left\| \rvx \right\|_2 + \left\| \rvr \cdot \rvx \right\|_2^2 \\
    &\le \left\| \rvx \cdot \rvx \right\|_2 + 2 \cdot \left\| \rvx \right\|_2^2 + \left\| \rvx \right\|_2^2 \\
    &\le 4 \cdot \left\| \rvx \right\|_2^2. \qedhere
\end{split}
\end{equation*}
\end{proof}

\begin{lem}[Lemma 1 in the paper]
\label{lem:logit_smoothness}
Let $\rvpi\left( \rvo^\prime \right)$ and $\rvpi\left( \rvo \right)$ be the softmax policies of any logit vectors $\rvo^\prime, \rvo \in \sR^h$, respectively. $\forall \rvr \in \left[ 0, 1\right]^h$,
\begin{equation*}
    \rvpi\left( \rvo^\prime \right)^\top \rvr \le \rvpi\left( \rvo \right)^\top \rvr + \left\langle \frac{d \rvpi\left( \rvo \right)^\top \rvr}{d \rvo}, \rvo^\prime - \rvo \right\rangle + \left\| \rvo^\prime - \rvo \right\|_2^2.
\end{equation*}
\end{lem}
\begin{proof}
Denote $\rvo_{\xi} = \rvo + \xi \left( \rvo^\prime - \rvo \right)$.
\begin{equation*}
\begin{split}
    &\left| \rvpi\left( \rvo^\prime \right)^\top \rvr - \rvpi\left( \rvo \right)^\top \rvr - \left\langle \frac{d \rvpi\left( \rvo \right)^\top \rvr}{d \rvo}, \rvo^\prime - \rvo \right\rangle \right| \\
    &\quad = \left| \int_0^1{ \frac{d \rvpi\left( \rvo + \xi \left( \rvo^\prime - \rvo \right) \right)^\top \rvr}{d \xi} d\xi} - \left\langle \frac{d \rvpi\left( \rvo \right)^\top \rvr}{d \rvo}, \rvo^\prime - \rvo \right\rangle \right| \\
    &\quad = \left| \int_0^1{ \left\langle \frac{d \rvpi\left( \rvo + \xi \left( \rvo^\prime - \rvo \right) \right)^\top \rvr}{d \left( \rvo + \xi \left( \rvo^\prime - \rvo \right) \right)}, \rvo^\prime - \rvo \right\rangle d\xi} - \left\langle \frac{d \rvpi\left( \rvo \right)^\top \rvr}{d \rvo}, \rvo^\prime - \rvo \right\rangle \right| \\
    &\quad = \left| \int_0^1{ \left\langle \frac{d \rvpi\left( \rvo_{\xi} \right)^\top \rvr}{d \rvo_{\xi}} - \frac{d \rvpi\left( \rvo \right)^\top \rvr}{d \rvo}, \rvo^\prime - \rvo \right\rangle d\xi} \right| \\
    &\quad \le \int_0^1{ \left| \left\langle \frac{d \rvpi\left( \rvo_{\xi} \right)^\top \rvr}{d \rvo_{\xi}} - \frac{d \rvpi\left( \rvo \right)^\top \rvr}{d \rvo}, \rvo^\prime - \rvo \right\rangle \right| d\xi} \\
    &\quad \le \int_0^1{ \left\| \frac{d \rvpi\left( \rvo_{\xi} \right)^\top \rvr}{d \rvo_{\xi}} - \frac{d \rvpi\left( \rvo \right)^\top \rvr}{d \rvo} \right\|_2 \cdot \left\| \rvo^\prime - \rvo \right\|_2 d\xi} \\
    &\quad = \int_0^1{ \left\| \gH\left( \rvpi\left( \rvo_{\xi} \right)\right) \rvr - \gH\left( \rvpi\left( \rvo \right)\right) \rvr \right\|_2 \cdot \left\| \rvo^\prime - \rvo \right\|_2 d\xi} \\
    &\quad = \int_0^1{ \left\| \int_0^1{\left\langle \frac{d \gH \left( \rvpi\left( \rvo + \mu\left( \rvo_{\xi} - \rvo \right) \right) \right) \rvr }{d \left( \rvo + \mu\left( \rvo_{\xi} - \rvo \right) \right)}, \rvo_{\xi} - \rvo \right\rangle d\mu} \right\|_2 \cdot \left\| \rvo^\prime - \rvo \right\|_2 d\xi} \\
    &\quad \le \int_0^1{  \int_0^1{ \left\| \left\langle \frac{d \gH \left( \rvpi\left( \rvo + \mu\left( \rvo_{\xi} - \rvo \right) \right) \right) \rvr }{d \left( \rvo + \mu\left( \rvo_{\xi} - \rvo \right) \right)}, \rvo_{\xi} - \rvo \right\rangle \right\|_2 d\mu} \cdot \left\| \rvo^\prime - \rvo \right\|_2 d\xi} \\
    &\quad \le \int_0^1{  \int_0^1{ \left\| \frac{d \gH \left( \rvpi\left( \rvo + \mu\left( \rvo_{\xi} - \rvo \right) \right) \right) \rvr }{d \left( \rvo + \mu\left( \rvo_{\xi} - \rvo \right) \right)} \right\|_2 \cdot \left\| \rvo_{\xi} - \rvo \right\|_2 d\mu} \cdot \left\| \rvo^\prime - \rvo \right\|_2 d\xi} \\
    &\quad = \int_0^1{  \int_0^1{ \left\| \frac{d \gH \left( \rvpi\left( \rvo + \mu\left( \rvo_{\xi} - \rvo \right) \right) \right) \rvr }{d \left( \rvo + \mu\left( \rvo_{\xi} - \rvo \right) \right)} \right\|_2 d\mu} \cdot \xi \cdot \left\| \rvo^\prime - \rvo \right\|_2^2 d\xi} \\
    &\quad \le \int_0^1{  \int_0^1{ 2 d\mu} \cdot \xi \cdot \left\| \rvo^\prime - \rvo \right\|_2^2 d\xi} \\
    &\quad = \left\| \rvo^\prime - \rvo \right\|_2^2. \qedhere
\end{split}
\end{equation*}
\end{proof}

\begin{lem}[Lemma 2 in the paper]
\label{lem:gradient_coupling}
	Define the pseudo policy gradient at step $t$ as,
\begin{equation*}
\begin{split}
	\frac{d \tilde{\ell}(t)}{d \rmW(t)} \triangleq \tilde{\rmD} \rmA^\top \left[ \Delta\left( \rvpi\left(\rmW(t)\right) \right) - \rvpi\left(\rmW(t)\right) \rvpi\left(\rmW(t)\right)^\top \right] \hat{\rvr}\left(t\right) \rvs^\top,
\end{split}
\end{equation*}
where $\tilde{\rmD} \in \sR^{h \times h}$ is a diagonal matrix, and $\tilde{\rmD}_{r,r} \triangleq \sI\left\{ \rvw_r(0)^\top \rvs > 0 \right\}$, $\forall r \in [m]$. The true policy gradient is,
\begin{equation*}
\begin{split}
    \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \triangleq  \rmD(t) \rmA^\top \left[ \Delta\left( \rvpi\left(\rmW(t)\right) \right) - \rvpi\left(\rmW(t)\right) \rvpi\left(\rmW(t)\right)^\top \right] \hat{\rvr}\left(t\right) \rvs^\top.
\end{split}
\end{equation*}
where $\rmD_{r,r}(t) \triangleq \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\}$, $\forall r \in [m]$. $\forall \tau > 0$, with probability at least $1 - \frac{\sqrt{2}\tau}{\sqrt{\pi}\sigma}$, $\forall t \le \frac{\tau}{ 2 \eta }$, $\forall r \in [m]$,
\begin{equation*}
	\frac{d\tilde{\ell}(t)}{d \rvw_r(t)} = \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rvw_r(t)},
\end{equation*}
where $\rvw_r(t)$ is the $r$th row vector of $\rmW(t)$.
\end{lem}
\begin{proof}
The $r$th row of the pseudo policy gradient as,
\begin{equation*}
	\frac{d \tilde{\ell}(t)}{d \rvw_r(t)} \triangleq \sum\limits_{k=1}^{h}{ \left[ \hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \cdot \left( \sum\limits_{k^\prime \not= k}^{h}{ \pi_{k^\prime}(t) \cdot \left( a_{k,r} - a_{k^\prime,r} \right)  } \right) \cdot \sI\left\{ \rvw_r(0)^\top \rvs > 0 \right\} \cdot \rvs \right] },
\end{equation*}
While the $r$th row of the true policy gradient is,
\begin{equation*}
	\frac{d \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rvw_r(t)} = \sum\limits_{k=1}^{h}{ \left[\hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \cdot \left( \sum\limits_{k^\prime \not= k}^{h}{ \pi_{k^\prime}(t) \cdot \left( a_{k,r} - a_{k^\prime,r} \right)  } \right) \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} \cdot \rvs \right] }.
\end{equation*}
The true policy gradient norm is upper bounded by the empirically expected reward,
\begin{equation*}
\begin{split}
	\left\| \frac{d \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rvw_r(t)} \right\|_2 &\le \sum\limits_{k=1}^{h}{ \left|\hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \cdot \sum\limits_{k^\prime \not= k}^{h}{ \pi_{k^\prime}(t) \cdot \left( a_{k,r} - a_{k^\prime,r} \right)  } \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} \right| \cdot \left\| \rvs \right\|_2 } \\
	&\le 2 \cdot \sum\limits_{k=1}^{h}{\hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \cdot \sum\limits_{k^\prime \not= k}^{h}{ \pi_{k^\prime}(t)  } \cdot \left\| \rvs \right\|_2  } \\
	&\le 2 \cdot \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right).
\end{split}
\end{equation*}
After $t$ times of gradient updates, the distance between $\rvw_r(t)$ and $\rvw_r(0)$ is also upper bounded,
\begin{equation*}
\begin{split}
	\left\| \rvw_r(t) - \rvw_r(0) \right\|_2 &\le \eta \cdot \sum\limits_{s=0}^{t-1}{\left\| \frac{d \rvpi\left( \rmW(s) \right)^\top \hat{\rvr}\left(s\right)}{d \rvw_r(s)} \right\|_2} \\
	&\le 2 \eta \cdot \sum\limits_{s=0}^{t-1}{ \rvpi\left(\rmW(s)\right)^\top \hat{\rvr}\left(s\right) } \\
	&\le 2 \eta t .
\end{split}
\end{equation*}
Since $\rvw_r(0)^\top \rvs \sim \gN(0, \sigma^2)$, $\pr\left\{ \left| \rvw_r(0)^\top \rvs \right| \le \tau\right\} \le  \frac{\sqrt{2}\tau}{\sqrt{\pi}\sigma}$,
\begin{equation*}
\begin{split}
	\pr\left\{ \left| \rvw_r(0)^\top \rvs \right| > \tau\right\} &= 1 - \pr\left\{ \left| \rvw_r(0)^\top \rvs \right| \le \tau\right\} \\
	&\ge 1 - \frac{\sqrt{2}\tau}{\sqrt{\pi}\sigma}.
\end{split}
\end{equation*}
Conditioning on the above event happens, i.e., $ \left| \rvw_r(0)^\top \rvs \right| > \tau$, let $t \le \frac{\tau}{ 2 \eta }$,
\begin{equation*}
\begin{split}
	\left| \left( \rvw_r(t) - \rvw_r(0) \right)^\top \rvs \right| &\le \left\| \rvw_r(t) - \rvw_r(0) \right\|_2 \cdot \left\| \rvs \right\|_2 \\
	&\le 2 \eta t \\
	&\le \tau < \left| \rvw_r(0)^\top \rvs \right|,
\end{split}
\end{equation*}
which implies if $\left| \rvw_r(0)^\top \rvs \right| > \tau$, then,
\begin{equation*}
\begin{split}
	\sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} &= \sI\left\{ \rvw_r(0)^\top \rvs  + \left( \rvw_r(t) - \rvw_r(0) \right)^\top \rvs > 0 \right\} \\
	&= \sI\left\{ \rvw_r(0)^\top \rvs > 0 \right\}. \qedhere
\end{split}
\end{equation*}
\end{proof}

\begin{lem}
\label{lem:inner_product_logit_difference_logit_derivative}
    $\rmW(t+1) = \rmW(t) + \eta \cdot \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)}$. Denote $\rvo(t+1)$ and $\rvo(t)$ as the logit vectors of $\rmW(t)$ and $\rmW(t+1)$ at state $\rvs$, respectively. $\forall t \le \frac{\tau}{ 2 \eta }$,
\begin{equation*}
\begin{split}
    \left\langle - \frac{d \rvpi\left( \rvo(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rvo(t)}, \rvo(t+1) - \rvo(t) \right\rangle = - \eta \left\| \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right\|_F^2.
\end{split}
\end{equation*}
\end{lem}
\begin{proof}
    First, the negative logit derivative is,
\begin{equation*}
\begin{split}
    - \frac{d \rvpi\left( \rvo(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rvo(t)} &= \left[\Delta\left( \rvpi\left( \rvo(t) \right) \right) - \rvpi\left( \rvo(t) \right) \rvpi\left( \rvo(t) \right)^\top \right] \hat{\rvr}\left(t\right) \\
    &= \left[\Delta\left( \rvpi\left( \rmW(t) \right) \right) - \rvpi\left( \rmW(t) \right) \rvpi\left( \rmW(t) \right)^\top \right] \hat{\rvr}\left(t\right).
\end{split}
\end{equation*}
Second, the logit difference of policy gradient update is,
\begin{equation*}
\begin{split}
    \rvo(t+1) - \rvo(t) &= \rmA \left[ \sigma\left(\rmW(t+1) \rvs \right) - \sigma\left( \rmW(t) \rvs \right)\right] \\
    &= \rmA \rmD(t) \left[ \rmW(t+1) - \rmW(t) \right] \rvs \\
    &= \eta \cdot \rmA \rmD(t) \left[ \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right] \rvs.
\end{split}
\end{equation*}
Combining the two above results,
\begin{equation*}
\begin{split}
    &\left\langle - \frac{d \rvpi\left( \rvo(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rvo(t)}, \rvo(t+1) - \rvo(t) \right\rangle \\
    &\quad = - \eta \cdot \hat{\rvr}\left(t\right)^\top \left[\Delta\left( \rvpi\left( \rmW(t) \right) \right) - \rvpi\left( \rmW(t) \right) \rvpi\left( \rmW(t) \right)^\top \right] \rmA \rmD(t) \left[ \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right] \rvs \\
    &\quad = - \eta \cdot \trace \left\{ \hat{\rvr}\left(t\right)^\top \left[\Delta\left( \rvpi\left( \rmW(t) \right) \right) - \rvpi\left( \rmW(t) \right) \rvpi\left( \rmW(t) \right)^\top \right] \rmA \rmD(t) \left[ \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right] \rvs \right\} \\
    &\quad = - \eta \cdot \trace \left\{ \rvs \hat{\rvr}\left(t\right)^\top \left[\Delta\left( \rvpi\left( \rmW(t) \right) \right) - \rvpi\left( \rmW(t) \right) \rvpi\left( \rmW(t) \right)^\top \right] \rmA \rmD(t) \left[ \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right]  \right\} \\
    &\quad = - \eta \left\langle \rmD(t) \rmA^\top \left[\Delta\left( \rvpi\left( \rmW(t) \right) \right) - \rvpi\left( \rmW(t) \right) \rvpi\left( \rmW(t) \right)^\top \right] \hat{\rvr}\left(t\right) \rvs^\top, \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right\rangle \\
    &\quad = - \eta \cdot \left\| \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right\|_F^2. \qedhere
\end{split}
\end{equation*}
\end{proof}

\begin{lem}
\label{lem:logit_upper_bound_parameter}
Denote $k_* \triangleq \argmax\limits_{k \in [h]}\left\{ \left| o_{k}^\prime - o_{k} \right| \right\}$. Let $\rvo$ and $\rvo^\prime$ be the logit vectors of $\rmW$, respectively, i.e.,
\begin{equation*}
\begin{split}
    &o_{k} = \sum\limits_{r=1}^{m}{ a_{k,r} \cdot \sigma\left( u_{r} \right)} = \sum\limits_{r=1}^{m}{ a_{k,r} \cdot \sigma\left(\rvw_r^\top \rvs \right)} \\
    &o_{k}^\prime = \sum\limits_{r=1}^{m}{ a_{k,r} \cdot \sigma\left( u_{r}^\prime \right)} = \sum\limits_{r=1}^{m}{ a_{k,r} \cdot \sigma\left({\rvw_r^\prime}^\top \rvs \right)},
\end{split}
\end{equation*}
$\forall k \in [h]$. Then,
\begin{equation*}
\begin{split}
    \left\| \rvo^\prime - \rvo \right\|_2^2 \le h m \left\| \rmW^\prime - \rmW \right\|_F^2.
\end{split}
\end{equation*}
\end{lem}
\begin{proof}
By the definition of the logit, and the $1$-Lipschitzness of ReLU,
\begin{equation*}
\begin{split}
    \left\| \rvo^\prime - \rvo \right\|_2^2 &\le \sum\limits_{k = 1}^{h}{ \left\| \rvo^\prime - \rvo \right\|_\infty^2} \\
    &= h \cdot \left| o_{k_*}^\prime - o_{k_*} \right|^2 \\
    &= h \cdot \left| \sum\limits_{r=1}^{m}{ a_{k_*,r} \cdot \left( \sigma\left({\rvw_r^\prime}^\top \rvs \right) - \sigma\left(\rvw_r^\top \rvs \right) \right)} \right|^2 \\
    &\le h \cdot \left( \sum\limits_{r=1}^{m}{ \left| a_{k_*,r} \right| \cdot \left| \sigma\left({\rvw_r^\prime}^\top \rvs\right) - \sigma\left({\rvw_r}^\top \rvs\right) \right|  } \right)^2 \\
    &\le h \cdot \left( \sum\limits_{r=1}^{m}{ \left| \left({\rvw_r^\prime} - \rvw_r \right)^\top \rvs\right|  } \right)^2 \\
    &\le h \cdot \left( \sum\limits_{r=1}^{m}{ \left\| {\rvw_r^\prime} - \rvw_r \right\|_2  } \right)^2 \\
    &\le h \cdot \left( \sqrt{m} \cdot \left\| \rmW^\prime - \rmW \right\|_F \right)^2 \\
    &= h m \cdot \left\| \rmW^\prime - \rmW \right\|_F^2. \qedhere
\end{split}
\end{equation*}
\end{proof}

\begin{lem}[Lemma 3 in the paper]
\label{lem:empirically_expected_reward_parameter_smoothness}
    $\rmW(t+1) = \rmW(t) + \eta \cdot \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)}$. $\forall t \le \frac{\tau}{ 2 \eta }$,
\begin{equation*}
\label{eq:parameter_smoothness}
\begin{split}
    \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right) \le \rvpi\left( \rmW(t+1) \right)^\top \hat{\rvr}\left(t\right) - \left( \eta - h m \eta^2 \right) \cdot \left\| \frac{d \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right\|_F^2.
\end{split}
\end{equation*}
\end{lem}
\begin{proof}
   Let $\rvr = - \hat{\rvr}\left(t\right)$ in \cref{lem:logit_smoothness}. By \cref{lem:inner_product_logit_difference_logit_derivative} and \cref{lem:logit_upper_bound_parameter},
\begin{equation*}
\begin{split}
    &\rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right) - \rvpi\left( \rmW(t+1) \right)^\top \hat{\rvr}\left(t\right) \\
    &\quad = \rvpi\left( \rmW(t+1) \right)^\top \left[ - \hat{\rvr}\left(t\right) \right] - \rvpi\left( \rmW(t) \right)^\top \left[ - \hat{\rvr}\left(t\right) \right]  \\
    &\quad = \rvpi\left( \rvo(t+1) \right)^\top \left[ - \hat{\rvr}\left(t\right) \right] - \rvpi\left( \rvo(t) \right)^\top \left[ - \hat{\rvr}\left(t\right) \right] \\
    &\quad \le \left\langle - \frac{d \rvpi\left( \rvo(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rvo(t)}, \rvo(t+1) - \rvo(t) \right\rangle + \left\| \rvo(t+1) - \rvo(t)  \right\|_2^2 \\
    &\quad \le - \eta \cdot \left\| \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right\|_F^2 + h m \left\| \rmW(t+1) - \rmW(t) \right\|_F^2 \\
    &\quad = - \eta \cdot \left\| \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right\|_F^2 + h m \eta^2 \left\| \frac{d \rvpi\left(\rmW(t)\right)^\top \hat{\rvr}\left(t\right)}{d \rmW(t)} \right\|_F^2. \qedhere
\end{split}
\end{equation*}
\end{proof}

\begin{lem}[Lemma 5 in the paper]
\label{lem:gradient_lower_bound}
	Denote $\hat{k}^*(t) \triangleq \argmax\limits_{k \in [h]}\left\{ \hat{r}_{k}\left(t\right) \right\}$, i.e., the optimal action using the estimated reward $ \hat{\rvr}\left(t\right)$. If $\pi_{\hat{k}^*(t)}\left(\rmW(t)\right) > c > 0$, with probability $\frac{3}{64} \in \Omega\left( 1 \right)$,
\begin{equation*}
\begin{split}
	\left\| \frac{d\tilde{\ell}\left(t\right)}{d \rvw_r(t)} \right\|_2 \ge c \cdot \left( \max\limits_{k \in \left[h\right]}\left\{ \hat{r}_k\left(t\right) \right\} - \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right) \right) .
\end{split}
\end{equation*}
\end{lem}
\begin{proof}
	 For conciseness, denote $\hat{k}^*(t)$ as $\hat{k}^*$. Rewrite $\frac{d\tilde{\ell}\left(t\right)}{d \rvw_r(t)} = \sum\limits_{k^
	\prime=1}^{h}{ a_{k^\prime,r} \cdot \rvp_{k^\prime, r} }$, where $\rvp_{k^\prime, r} \in \sR^d$ is defined as, 
\begin{equation*}
	\rvp_{k^\prime, r} \triangleq \sum\limits_{k=1}^{h}{ \left[ \hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \cdot v_{k^\prime,k}(t) \cdot \sI\left\{ \rvw_r(0)^\top \rvs > 0 \right\} \cdot \rvs \right] },
\end{equation*}
and $v_{k^\prime,k}(t)$ is defined as,
\begin{equation*}
	v_{k^\prime,k}(t) = \begin{cases}
    1 - \pi_{k^\prime}(t), & \text{if $k^\prime = k$}, \\
    - \pi_{k^\prime}(t), & \text{otherwise}.
  \end{cases}
\end{equation*}
By the randomness of $a_{k^\prime,r}$,
\begin{equation}
\label{eq:gradient_p_lowerbound}
\begin{split}
	\left\| \frac{d\tilde{\ell}\left(t\right)}{d \rvw_r(t)} \right\|_2 &= \left\| \sum\limits_{k^
	\prime=1}^{h}{ a_{k^\prime,r} \cdot \rvp_{k^\prime, r} } \right\|_2 \\
	&\ge \left| a_{\hat{k}^*,r} \right| \cdot \left\| \rvp_{\hat{k}^*, r}\right\|_2 \\
	&= \left\| \rvp_{\hat{k}^*, r}\right\|_2,
\end{split}
\end{equation}
with probability $\frac{1}{2}$. Define $h_{\hat{k}^*,r}$ as follows,
\begin{equation}
\label{eq:h_auxiliary}
\begin{split}
	h_{\hat{k}^*,r} &\triangleq \rvw_r(0)^\top \rvp_{\hat{k}^*, r} \\
	&=  \sum\limits_{k=1}^{h}{ \left[ \hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \cdot v_{\hat{k}^*,k}(t) \cdot \sigma( \rvw_r(0)^\top \rvs ) \right] }.
\end{split}
\end{equation}
Denote $x \triangleq \rvw_r(0)^\top \rvs \sim \gN(0, \sigma^2)$. Note that $h_{\hat{k}^*,r}$ is a convex function of $x$. Moreover,
\begin{equation*}
\begin{split}
	&\sum\limits_{k=1}^{h}{ \left[ \hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \cdot v_{\hat{k}^*,k}(t) \right] } \\
	&\quad = \hat{r}_{\hat{k}^*}\left(t\right) \cdot \pi_{\hat{k}^*}(t) \cdot v_{\hat{k}^*,\hat{k}^*}(t) + \sum\limits_{k\not=\hat{k}^*}{ \left[ \hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \cdot v_{\hat{k}^*,k}(t) \right] } \\
	&\quad = \hat{r}_{\hat{k}^*}\left(t\right) \cdot \pi_{\hat{k}^*}(t) \cdot \left( 1 - \pi_{\hat{k}^*}(t) \right) - \pi_{\hat{k}^*}(t) \cdot \sum\limits_{k\not=\hat{k}^*}{ \left[ \hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \right] } \\
	&\quad = \pi_{\hat{k}^*}(t) \cdot \left( \hat{r}_{\hat{k}^*}\left(t\right) - \sum\limits_{k=1}^{h}{ \left[ \hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \right] } \right) \\
	&\quad = \pi_{\hat{k}^*}(t) \cdot \left( \max\limits_{k \in \left[h\right]}\left\{ \hat{r}_k\left(t\right) \right\} - \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)  \right).
\end{split}
\end{equation*}
By assumption, if $\pi_{\hat{k}^*}(t) > c > 0$, then ,
\begin{equation*}
\begin{split}
	\left| \partial{h_{\hat{k}^*,r}}_{\max}{(0)} - \partial{h_{\hat{k}^*,r}}_{\min}{(0)} \right| &= \left| \sum\limits_{k=1}^{h}{ \left[  \hat{r}_{k}\left(t\right) \cdot \pi_{k}(t) \cdot v_{\hat{k}^*,k}(t) \right] } \right| \\
	&= \pi_{\hat{k}^*}(t) \cdot \left( \max\limits_{k \in \left[h\right]}\left\{ \hat{r}_k\left(t\right) \right\} - \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)  \right) \\
	&\ge c \cdot \left( \max\limits_{k \in \left[h\right]}\left\{ \hat{r}_k\left(t\right) \right\} - \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)  \right).
\end{split}
\end{equation*}
where $\partial{h_{\hat{k}^*,r}}_{\max}{(0)} = \max\left\{ \partial{h_{\hat{k}^*,r}}{(0)} \right\}$, $\partial{h_{\hat{k}^*,r}}_{\min}{(0)} = \min\left\{ \partial{h_{\hat{k}^*,r}}{(0)} \right\}$ are the maximum and minimum of $\partial{h_{\hat{k}^*,r}}{(0)}$, i.e., the subdifferential of $h_{\hat{k}^*,r}$ at $0$. Now consider \cref{eq:h_auxiliary}, and uniformly randomly generate $x$ in $\left[ -\tau, \tau \right]$, $\forall \tau > 0$, by \cref{lem:non_smooth_convex},
\begin{equation}
\label{eq:h_regret_lower_bound}
\begin{split}
	\probability\limits_{x \sim  \gU[-\tau, \tau]}\left\{ \left|  h_{\hat{k}^*,r} \right| \ge \frac{c\tau}{8} \cdot \left( \max\limits_{k \in \left[h\right]}\left\{ \hat{r}_k\left(t\right) \right\} - \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)  \right) \right\} > \frac{1}{8}.
\end{split}
\end{equation}
Finally, $h_{\hat{k}^*,r} \sim \gN\left( 0, \left\| \rvp_{\hat{k}^*, r} \right\|_2^2 \cdot \sigma^2 \right)$, with probability at least $\frac{3}{4}$,
\begin{equation}
\label{eq:p_h_lower_bound}
\begin{split}
	\left| h_{\hat{k}^*,r} \right| < \sqrt{2 \log{8}} \cdot \left\| \rvp_{\hat{k}^*, r} \right\|_2 \cdot \sigma.
\end{split}
\end{equation}
Combining \cref{eq:gradient_p_lowerbound}, \cref{eq:h_regret_lower_bound} and \cref{eq:p_h_lower_bound}, we have,
\begin{equation*}
\begin{split}
	\left\| \frac{d\tilde{\ell}\left(t\right)}{d \rvw_r(t)} \right\|_2 &\ge \left\| \rvp_{\hat{k}^*, r}\right\|_2 \\
	&> \frac{\left| h_{\hat{k}^*,r} \right|}{\sqrt{2 \log{8}} \sigma} \\
	&\ge \frac{c\tau}{8 \sqrt{2 \log{8}} \sigma} \cdot \left( \max\limits_{k \in \left[h\right]}\left\{ \hat{r}_k\left(t\right) \right\} - \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)  \right),
\end{split}
\end{equation*}
with probability at least $\frac{1}{2}  \cdot \frac{1}{8} \cdot \frac{3}{4} $. Taking $\tau = 8 \sqrt{2 \log{8}} \sigma$ completes the proof.
\end{proof}

\begin{lem}
\label{lem:non_smooth_convex}
	Let $\phi(x) : \sR \to \sR$ be a convex function non-smooth at $0$. Define,
\begin{equation*}
\begin{split}
	\partial\phi_{\max}{(0)} = \max\left\{ \partial\phi(0) \right\}, \quad \partial\phi_{\min}{(0)} = \min\left\{ \partial\phi(0) \right\},
\end{split}
\end{equation*}	
where $\partial\phi(0)$ is the subdifferential of $\phi$ at $0$. Then we have,
\begin{equation*}
\begin{split}
	\probability\limits_{x \sim \gU[-\tau, \tau]}\left\{ \left| \phi(x) \right| \ge \frac{ \left( \partial\phi_{\max}{(0)} - \partial\phi_{\min}{(0)} \right) \tau}{8} \right\} \ge \frac{1}{8}.
\end{split}
\end{equation*}	
\end{lem}
\begin{proof}
	Denote $\rho = \partial\phi_{\max}{(0)} - \partial\phi_{\min}{(0)}$, we have $\partial\phi_{\max}{(0)} \ge \frac{\rho}{2}$ or $\partial\phi_{\min}{(0)} \le - \frac{\rho}{2}$. If $\partial\phi_{\min}{(0)} \le - \frac{\rho}{2}$, then $-\phi$ will satisfy the first case. So we prove for $\partial\phi_{\max}{(0)} \ge \frac{\rho}{2}$. Define $\hat{\phi}(x) = \phi(x) - \phi(0)$. $\forall x > 0$,
\begin{equation*}
\begin{split}
	\hat{\phi}(x) \ge \hat{\phi}(0) + \frac{\rho}{2} \cdot \left( x - 0\right) = \frac{\rho x}{2} \ge 0.
\end{split}
\end{equation*}
If $\phi(0) \ge 0$, then $\forall x \in \left[\frac{\tau}{2}, \tau \right]$,
\begin{equation*}
\begin{split}
	\left| \phi(x) \right| = \left| \hat{\phi}(x) + \phi(0) \right| = \hat{\phi}(x) + \phi(0) \ge \frac{\rho x}{2} \ge \frac{\rho \tau}{4}.
\end{split}
\end{equation*}
If $\phi(0) < 0$, then $\phi(x_0) = 0$ for some $x_0 > 0$. If $x_0 < \frac{\tau}{2}$, $\forall x \in \left[x_0 + \frac{\tau}{4}, \tau \right]$,
\begin{equation*}
\begin{split}
	\left| \phi(x) \right| =  \phi(x) \ge \phi(x_0) + \phi^\prime(x_0) \cdot \left( x - x_0 \right) \ge \frac{\rho \tau}{8}.
\end{split}
\end{equation*}
If $x_0 \ge \frac{\tau}{2}$, then $\phi(0) \le - \frac{\rho}{2} \cdot x_0 \le - \frac{\rho\tau}{4}$, $\forall x \in \left[0, x_0 - \frac{\tau}{4} \right]$,
\begin{equation*}
	\left| \phi(x) \right| \ge \left| \frac{-\phi(0)}{x_0} \left( x - x_0 \right) \right| = \frac{-\phi(0)}{x_0} \left( x_0 - x \right) \ge \frac{\rho\tau}{8}. \qedhere
\end{equation*}
\end{proof}

\begin{lem}
\label{lem:logit_l2_loss_parameter_smoothness}
$\rmW(t+1) \leftarrow \rmW(t) - \eta \cdot \frac{d \left\{ \frac{1}{2} \left\| \rvo\left( \rmW\left(t\right)\right) - \hat{\rvr}\left(t\right) \right\|_2^2 \right\}}{d \rmW(t)}$, where $\eta = \frac{1}{h m}$. $\forall t \le \frac{\tau}{2 \eta}$,
\begin{equation*}
\begin{split}
    \frac{1}{2} \left\| \rvo\left( \rmW\left(t+1\right) \right) - \hat{\rvr}\left(t\right) \right\|_2^2 \le \left( 1 - \frac{1}{2 h m} \right) \cdot \frac{1}{2} \left\| \rvo\left( \rmW\left(t\right) \right) - \hat{\rvr}\left(t\right) \right\|_2^2.
\end{split}
\end{equation*}
\end{lem}
\begin{proof}
According to \cref{lem:logit_upper_bound_parameter},
\begin{equation*}
\begin{split}
    &\frac{1}{2} \left\| \rvo\left( \rmW\left(t+1\right) \right) - \hat{\rvr}\left(t\right) \right\|_2^2 - \frac{1}{2} \left\| \rvo\left( \rmW\left(t\right) \right) - \hat{\rvr}\left(t\right) \right\|_2^2 \\
    &\quad = \left\langle \rvo\left( \rmW\left(t\right) \right) - \hat{\rvr}\left(t\right), \rvo\left( \rmW\left(t+1\right) \right) - \rvo\left( \rmW\left(t\right) \right) \right\rangle + \frac{1}{2} \left\| \rvo\left( \rmW\left(t+1\right) \right) - \rvo\left( \rmW\left(t\right) \right) \right\|_2^2 \\
    &\quad \le \left\langle \rvo\left( \rmW\left(t\right) \right) - \hat{\rvr}\left(t\right), - \eta \cdot \rmA \rmD(t) \left[ \frac{d \left\{ \frac{1}{2} \left\| \rvo\left( \rmW\left(t\right)\right) - \hat{\rvr}\left(t\right) \right\|_2^2 \right\}}{d \rmW(t)} \right] \rvs \right\rangle + \frac{h m \eta^2}{2} \left\| \frac{d \left\{ \frac{1}{2} \left\| \rvo\left( \rmW\left(t\right)\right) - \hat{\rvr}\left(t\right) \right\|_2^2 \right\}}{d \rmW(t)}  \right\|_F^2 \\
    &\quad = - \left( \eta - \frac{h m \eta^2}{2} \right) \left\| \frac{d \left\{ \frac{1}{2} \left\| \rvo\left( \rmW\left(t\right)\right) - \hat{\rvr}\left(t\right) \right\|_2^2 \right\}}{d \rmW(t)}  \right\|_F^2 \\
    &\quad = - \frac{1}{2 h m} \left\| \frac{d \left\{ \frac{1}{2} \left\| \rvo\left( \rmW\left(t\right)\right) - \hat{\rvr}\left(t\right) \right\|_2^2 \right\}}{d \rmW(t)}  \right\|_F^2 \\
    &\quad \le - \frac{1}{2 h m} \cdot \frac{1}{2} \left\| \rvo\left( \rmW\left(t\right)\right) - \hat{\rvr}\left(t\right) \right\|_2^2. \qedhere
\end{split}
\end{equation*}
\end{proof}

\section{Policy Gradient}

\subsection{One Form}

The policy gradient with respect to $\rvw_r(t)$ is,
\begin{equation}
\label{eq:gradient_form_one}
\begin{split}
	\frac{d \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rvw_r(t)} &=  \sum\limits_{k=1}^{h}\left[ \hat{r}_k\left(t\right) \cdot \frac{d \pi_k(t)}{d \rvw_r(t)} \right]  \\
	&= \sum\limits_{k=1}^{h}\left[ \hat{r}_k\left(t\right) \cdot \frac{d}{d \rvw_r(t)} \left\{ \frac{\exp\left\{ o_k(t) \right\}}{\sum\limits_{k^\prime = 1}^{h}{\exp\left\{ o_{k^\prime}(t) \right\}}} \right\} \right] \\
	&= \sum\limits_{k=1}^{h}\left[ \hat{r}_k\left(t\right) \cdot \frac{ \exp\left\{ o_k(t) \right\} \cdot a_{k,r} \cdot \rvs \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} \cdot \left( \sum\limits_{k^\prime = 1}^{h}{\exp\left\{ o_{k^\prime}(t) \right\}} \right) }{ \left( \sum\limits_{k^\prime = 1}^{h}{\exp\left\{ o_{k^\prime}(t) \right\}} \right)^2 } \right] \\
	&\quad -\sum\limits_{k=1}^{h}\left[ \hat{r}_k\left(t\right) \cdot \frac{ \exp\left\{ o_k(t) \right\} \cdot \sum\limits_{k^\prime = 1}^{h}{\exp\left\{ o_{k^\prime}(t) \right\}} \cdot a_{k^\prime,r} \cdot \rvs \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} }{ \left( \sum\limits_{k^\prime = 1}^{h}{\exp\left\{ o_{k^\prime}(t) \right\}} \right)^2 } \right] \\
	&= \sum\limits_{k=1}^{h}{ \left[ \hat{r}_k\left(t\right) \cdot \pi_k(t) \cdot \left( \sum\limits_{k^\prime = 1}^{h}{ a_{k,r} \cdot \pi_{k^\prime}(t) } - \sum\limits_{k^\prime = 1}^{h}{ a_{k^\prime,r} \cdot \pi_{k^\prime}(t) } \right) \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} \cdot \rvs \right] } \\
	&= \sum\limits_{k=1}^{h}{ \left[ \hat{r}_k\left(t\right) \cdot \pi_k(t) \cdot \left( \sum\limits_{k^\prime \not= k}^{h}{ \pi_{k^\prime}(t) \cdot \left( a_{k,r} - a_{k^\prime,r} \right)  } \right) \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} \cdot \rvs \right] } \\
	&= \sum\limits_{k=1}^{h}{ \left[ \hat{r}_k\left(t\right) \cdot \pi_k(t) \cdot \left( \sum\limits_{k^\prime = 1}^{h}{ a_{k^\prime,r}  \cdot v_{k^\prime,k}(t) } \right) \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} \cdot \rvs \right] },
\end{split}
\end{equation}
where $v_{k^\prime,k}(t)$ is defined as,
\begin{equation*}
	v_{k^\prime,k}(t) = \begin{cases}
    1 - \pi_{k^\prime}(t), & \text{if $k^\prime = k$}, \\
    - \pi_{k^\prime}(t), & \text{otherwise}.
  \end{cases}
\end{equation*}

\subsection{Another Form}

First note that, $\forall k \in [h]$,
\begin{equation*}
\begin{split}
    \frac{d \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)}{d o_k(t)} &= \sum\limits_{k^\prime = 1}^{h}{ \hat{r}_{k^\prime}\left(t\right) \cdot \frac{d \pi_{k^\prime}(t) }{d o_k(t)}} \\
    &= \sum\limits_{k^\prime = 1}^{h}{ \hat{r}_{k^\prime}\left(t\right) \cdot \frac{d }{d o_k(t)}} \left\{ \frac{\exp\left\{ o_{k^\prime}(t) \right\}}{\sum\limits_{k^\prime = 1}^{h}{\exp\left\{ o_{k^\prime}(t) \right\}}} \right\} \\
    &= \hat{r}_{k}\left(t\right) \cdot \frac{ \exp\left\{ o_k(t) \right\} \cdot \left( \sum\limits_{k^\prime = 1}^{h}{\exp\left\{ o_{k^\prime}(t) \right\}} \right) - \exp\left\{ o_k(t) \right\} \cdot \exp\left\{ o_k(t) \right\} }{ \left( \sum\limits_{k^\prime = 1}^{h}{\exp\left\{ o_{k^\prime}(t) \right\}} \right)^2 } \\
    &\quad - \sum\limits_{k^\prime \not= k}{ \hat{r}_{k^\prime}\left(t\right) \cdot \frac{\exp\left\{ o_{k^\prime}(t) \right\} \cdot \exp\left\{ o_k(t) \right\} }{ \left( \sum\limits_{k^\prime = 1}^{h}{\exp\left\{ o_{k^\prime}(t) \right\}} \right)^2 }} \\
    &= \hat{r}_{k}\left(t\right) \cdot \left( \pi_k(t) - \pi_k(t)^2 \right) - \sum\limits_{k^\prime \not= k}{ \hat{r}_{k^\prime}\left(t\right) \cdot \pi_{k^\prime}(t) \cdot \pi_k(t) } \\
    &= \pi_k(t) \cdot \left( \hat{r}_{k}\left(t\right) - \rvpi(t)^\top \hat{\rvr}\left(t\right) \right).
\end{split}
\end{equation*}

\noindent Using the vector derivative notations,
\begin{equation*}
\begin{split}
    \frac{d \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rvo(t)} &= \left( \Delta\left( \rvpi(t) \right) - \rvpi(t) \rvpi(t)^\top \right) \hat{\rvr}\left(t\right).
\end{split}
\end{equation*}

\noindent Also note that, $\forall r \in [m]$, $\forall k \in [h]$,
\begin{equation*}
\begin{split}
    \frac{d o_k(t)}{d \rvw_r(t)} &= a_{k,r} \cdot \frac{d u_{r}(t)}{d \rvw_r(t)} \\
    &= a_{k,r} \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} \cdot \rvs.
\end{split}
\end{equation*}

\noindent Thus the gradient with respect to $\rvw_r(t)$ is,
\begin{equation}
\label{eq:gradient_form_two}
\begin{split}
    \frac{d \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)}{d \rvw_r(t)} &=  \sum\limits_{k=1}^{h}{ \frac{d \rvpi\left( \rmW(t) \right)^\top \hat{\rvr}\left(t\right)}{d o_k(t)} \cdot \frac{d o_k(t)}{d \rvw_r(t)} }  \\
    &= \sum\limits_{k=1}^{h}{ \left[ \pi_k(t) \cdot \left( \hat{r}_{k}\left(t\right) - \rvpi(t)^\top \hat{\rvr}\left(t\right) \right) \cdot a_{k,r} \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} \cdot \rvs  \right] } \\
    &= \hat{\rvr}^\top \left( \Delta\left( \rvpi(t) \right) - \rvpi(t) \rvpi(t)^\top \right) \rva_{\cdot, r} \cdot \sI\left\{ \rvw_r(t)^\top \rvs > 0 \right\} \cdot \rvs,
\end{split}
\end{equation}
where $\rva_{\cdot, r} \triangleq \left( a_{1,r}, a_{2,r}, \dots, a_{h,r} \right)^\top \in \sR^h$. It is easy to check that \cref{eq:gradient_form_one} and \cref{eq:gradient_form_two} are equivalent.

\end{document}
