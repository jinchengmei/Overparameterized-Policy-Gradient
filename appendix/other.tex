\documentclass[10pt]{article}
\usepackage[usenames]{color} %used for font color
\usepackage{amssymb} %maths
\usepackage{amsmath} %maths
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage[utf8]{inputenc} %useful to type directly diacritic characters
\usepackage{algorithm,algorithmic}
\usepackage[capitalize]{cleveref}
\crefname{prop}{Proposition}{Propositions}
\crefname{thm}{Theorem}{Theorems}
\crefname{lem}{Lemma}{Lemmas}
\crefname{algorithm}{Algorithm}{Algorithms}

\def\rva{{\mathbf{a}}}
\def\rvo{{\mathbf{o}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvu{{\mathbf{u}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvg{{\mathbf{g}}}
\def\rvo{{\mathbf{o}}}
\def\rvone{{\mathbf{1}}}
\def\rvzero{{\mathbf{0}}}
\def\rvtilder{{\tilde{\mathbf{r}}}}

\def\rvp{{\mathbf{p}}}

\def\pr{{\text{Pr}}}
\def\r{{\text{R}}}

\def\regret{{\text{Regret}}}

\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{defi}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{remk}{Remark}


\def\rvpi{{\boldsymbol{\pi}}}

\def\rmA{{\mathbf{A}}}
\def\rmI{{\mathbf{I}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}

\def\sE{{\mathbb{E}}}
\def\sR{{\mathbb{R}}}
\def\sI{{\mathbb{I}}}

\def\gH{{\mathcal{H}}}
\def\gN{{\mathcal{N}}}
\def\gE{{\mathcal{E}}}
\def\gU{{\mathcal{U}}}


\title{Overparameterized Policy Gradient}
\author{}
\date{December 2018}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\probability}{Pr}
\DeclareMathOperator*{\expectation}{\sE}

\begin{document}

%\maketitle

\begin{lem}
    Given weights $\rmW \triangleq \left[ \rvw_1, \rvw_2, \dots, \rvw_m \right]$, and $\rmW^\prime \triangleq \left[ \rvw_1^\prime, \rvw_2^\prime, \dots, \rvw_m^\prime \right]$. Denote $\rvpi_i\left( \rmW \right)$ and $\rvpi_i\left( \rmW^\prime \right)$ as the neural network policies parameterized by $\rmW$ and $\rmW^\prime$, respectively. $\forall i \in [n]$,
\begin{equation*}
\begin{split}
    \rvpi_i\left( \rmW^\prime \right)^\top \rvtilder_i \le \rvpi_i\left( \rmW \right)^\top \rvtilder_i + 4 h  \sqrt{m \log{2m}} \cdot \left\| \rmW^\prime - \rmW \right\|_F.
\end{split}
\end{equation*}
\end{lem}
\begin{proof}
    Denote $\rvo_i$ and $\rvo_i^\prime$ as the logits of $\rmW$ and $\rmW^\prime$, respectively. $\forall k \in [h]$,
\begin{equation*}
\begin{split}
    \pi_{i,k}\left( \rmW \right) = \frac{\exp\left\{ o_{i,k} \right\}}{\sum\limits_{k^\prime=1}^{h}{ \exp\left\{ o_{i,k^\prime} \right\} }}, &\quad \pi_{i,k}\left( \rmW^\prime \right) = \frac{\exp\left\{ o_{i,k}^\prime \right\}}{\sum\limits_{k^\prime=1}^{h}{ \exp\left\{ o_{i,k^\prime}^\prime \right\} }}, \\
    o_{i,k} = \sum\limits_{r=1}^{m}{a_{k,r} \cdot u_{i,r}} = \sum\limits_{r=1}^{m}{a_{k,r} \cdot \sigma\left( \rvw_r^\top \rvs_i \right)}, &\quad o_{i,k}^\prime = \sum\limits_{r=1}^{m}{a_{k,r} \cdot u_{i,r}^\prime} = \sum\limits_{r=1}^{m}{a_{k,r} \cdot \sigma\left( {\rvw_r^\prime}^\top \rvs_i \right)}.
\end{split}
\end{equation*}
Define $k_*^i = \argmax\limits_{k \in [h]}\left\{ \left| o_{i,k}^\prime - o_{i,k} \right| \right\}$, $\forall i \in [n]$,
\begin{equation*}
\begin{split}
    &\left| \rvpi_i\left( \rmW^\prime \right)^\top \rvtilder_i - \rvpi_i\left( \rmW \right)^\top \rvtilder_i \right| \le \left\| \rvpi_i\left( \rmW^\prime \right) - \rvpi_i\left( \rmW \right) \right\|_1 \cdot \left\| \rvtilder_i \right\|_\infty \\
    &\le \left\| \log{ \rvpi_i\left( \rmW^\prime \right)} - \log{ \rvpi_i\left( \rmW \right) }  \right\|_1 \\
    &= \left\| \rvo_i^\prime - \rvo_i + \left( \log{ \sum\limits_{k^\prime=1}^{h}{ \exp\left\{ o_{i,k^\prime} \right\} } } - \log{ \sum\limits_{k^\prime=1}^{h}{ \exp\left\{ o_{i,k^\prime}^\prime \right\} } } \right) \cdot \rvone\right\|_1 \\
    &\le \left\| \rvo_i^\prime - \rvo_i \right\|_1 + h \cdot \left| \log{ \sum\limits_{k^\prime=1}^{h}{ \exp\left\{ o_{i,k^\prime} \right\} } } - \log{ \sum\limits_{k^\prime=1}^{h}{ \exp\left\{ o_{i,k^\prime}^\prime \right\} } } \right| \\
    &\le \left\| \rvo_i^\prime - \rvo_i \right\|_1 + h \cdot \left\| \rvo_i^\prime - \rvo_i \right\|_\infty \\
    &\le 2 h \cdot \left\| \rvo_i^\prime - \rvo_i \right\|_\infty \\
    &= 2 h \cdot \left| o_{i,k_*^i}^\prime - o_{i,k_*^i} \right| \\
    &= 2 h \cdot \left| \sum\limits_{r=1}^{m}{a_{k_*^i,r} \left( \sigma\left({\rvw_r^\prime}^\top \rvs_i\right) - \sigma\left({\rvw_r}^\top \rvs_i\right) \right) } \right| \\
    &\le 2 h \cdot \sum\limits_{r=1}^{m}{ \left| a_{k_*^i,r} \right| \cdot \left| \sigma\left({\rvw_r^\prime}^\top \rvs_i\right) - \sigma\left({\rvw_r}^\top \rvs_i\right) \right| } \\
    &\le 2 h \cdot 2 \sqrt{\log{2m}} \cdot \sum\limits_{r=1}^{m}{ \left| {\rvw_r^\prime}^\top \rvs_i - {\rvw_r}^\top \rvs_i \right| } \quad \left( \text{w.p. at least } 1 - \frac{1}{m} \right) \\
    &\le 4h \sqrt{\log{2m}} \cdot \sum\limits_{r=1}^{m}{ \left\| \rvw_r^\prime - \rvw_r \right\|_2 } \\
    &\le 4h \sqrt{\log{2m}} \cdot \sqrt{m} \cdot \left\| \rmW^\prime - \rmW \right\|_F. \qedhere
\end{split}
\end{equation*}
\end{proof}

\begin{lem}
\label{lem:semi_smoothness}
     $\forall$ $\rmW$, $\rmW^\prime \in \sR^{d \times m}$, $\forall i \in [n]$,
\begin{equation*}
\begin{split}
    \rvpi_i\left( \rmW^\prime \right)^\top \rvtilder_i &\le \rvpi_i\left( \rmW \right)^\top \rvtilder_i + \left\langle \frac{d \rvpi_i\left( \rmW \right)^\top \rvtilder_i }{d\left( \rmW \right)}, \rmW^\prime - \rmW \right\rangle \\
    &\quad + 4 \sqrt{m \log{\left(4h\right)}} \cdot \rvpi_i\left( \rmW \right)^\top \rvtilder_i \cdot \left\| \rmW^\prime - \rmW \right\|_F \\
    &+ 4 h m \sqrt{\log{\left(2m\right)} \log{\left(4h\right)}} \cdot \left\| \rmW^\prime - \rmW \right\|_F^2.
\end{split}
\end{equation*}
\end{lem}
\begin{proof}
Denote $\bar{\rmW}_\xi \triangleq \rmW +  \xi \cdot\left( \rmW^\prime - \rmW \right) = \left[ \bar{\rvw}_1, \bar{\rvw}_2, \dots, \bar{\rvw}_m \right]$.
\begin{equation*}
\begin{split}
    &\left| \rvpi_i\left( \rmW^\prime \right)^\top \rvtilder_i - \rvpi_i\left( \rmW \right)^\top \rvtilder_i \right| = \left| \int_{0}^{1} { \frac{ d \rvpi_i\left( \rmW +  \xi \cdot\left( \rmW^\prime - \rmW \right) \right)^\top \rvtilder_i }{d\xi} } d\xi \right| \\
    &= \left| \int_{0}^{1}{ \left\langle \frac{d \rvpi_i\left( \rmW +  \xi \cdot\left( \rmW^\prime - \rmW \right) \right)^\top \rvtilder_i }{d\left( \rmW +  \xi \cdot\left( \rmW^\prime - \rmW \right) \right)}, \rmW^\prime - \rmW \right\rangle d\xi} \right| \\
    &\le \int_{0}^{1}{ \left| \left\langle \frac{d \rvpi_i\left( \rmW +  \xi \cdot\left( \rmW^\prime - \rmW \right) \right)^\top \rvtilder_i }{d\left( \rmW +  \xi \cdot\left( \rmW^\prime - \rmW \right) \right)}, \rmW^\prime - \rmW \right\rangle \right| d\xi} \\
    &\le \int_{0}^{1}{  \left\| \frac{d \rvpi_i\left( \bar{\rmW}_\xi \right)^\top \rvtilder_i }{d\left( \bar{\rmW}_\xi \right)} \right\|_F \cdot \left\| \rmW^\prime - \rmW \right\|_F d\xi} \\
    &= \int_{0}^{1}{  \sqrt{ \sum\limits_{r=1}^{m}{\left\| \frac{d \rvpi_i\left( \bar{\rmW}_\xi \right)^\top \rvtilder_i }{d \bar{\rvw}_r}\right\|_2^2 } } \cdot \left\| \rmW^\prime - \rmW \right\|_F d\xi} \\
    &\le \int_{0}^{1}{  \sqrt{ \sum\limits_{r=1}^{m}{\left( 2 \sqrt{\log{\left(4h\right)}} \cdot \rvpi_i\left( \bar{\rmW}_\xi \right)^\top \rvtilder_i \right)^2 } } \cdot \left\| \rmW^\prime - \rmW \right\|_F d\xi} \\
    &= 2 \sqrt{m \log{\left(4h\right)}} \cdot \left\| \rmW^\prime - \rmW \right\|_F  \cdot \int_{0}^{1}{ \rvpi_i\left( \bar{\rmW}_\xi \right)^\top \rvtilder_i d\xi} \\
    &\le 2 \sqrt{m \log{\left(4h\right)}} \cdot \left\| \rmW^\prime - \rmW \right\|_F  \cdot \int_{0}^{1}{ \left( \rvpi_i\left( \rmW \right)^\top \rvtilder_i + 4 h \sqrt{m \log{\left(2m\right)}} \cdot \left\| \bar{\rmW}_\xi - \rmW \right\|_F \right) d\xi} \\
    &\le 2 \sqrt{m \log{\left(4h\right)}} \cdot \rvpi_i\left( \rmW \right)^\top \rvtilder_i \cdot \left\| \rmW^\prime - \rmW \right\|_F + 4 h m   \sqrt{\log{\left(2m\right)} \log{\left(4h\right)}} \cdot \left\| \rmW^\prime - \rmW \right\|_F^2.
\end{split}
\end{equation*}
Combine the above with the following,
\begin{equation*}
\begin{split}
    \left| \left\langle \frac{d \rvpi_i\left( \rmW \right)^\top \rvtilder_i }{d\left( \rmW \right)}, \rmW^\prime - \rmW \right\rangle \right| &\le \left\| \frac{d \rvpi_i\left( \rmW \right)^\top \rvtilder_i }{d\left( \rmW \right)} \right\|_F \cdot \left\| \rmW^\prime - \rmW \right\|_F \\
    &\le 2 \sqrt{m \log{\left(4h\right)}} \cdot \rvpi_i\left( \rmW \right)^\top \rvtilder_i \cdot \left\| \rmW^\prime - \rmW \right\|_F. \qedhere
\end{split}
\end{equation*}
\end{proof}

\begin{thm}
\label{thm:surrogate_expected_loss_convergence}
    Suppose $m \in \Theta\left( \frac{n^{10}}{c^4 \delta^4 \varepsilon^2} \right)$, $\eta = \frac{c_t^2 \delta^2}{16 n^4 h m}$, During the playing-learning phase, $\forall t \ge T^{\frac{2}{3} + \beta}$, denote $t^\prime \triangleq t - T^{\frac{2}{3} + \beta} \ge 0$. After $t^\prime = \frac{2n^4}{\eta m c^2 \delta^2 \varepsilon}$ iterations, $\rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i \le \varepsilon$, $\forall \varepsilon > 0$.
\end{thm}
\begin{proof}
    By \cref{lem:gradient_coupling}, let $\tau = \frac{\sigma}{n}$, there are $\Omega\left( m \right)$ of $\rvw_r(t)$ such that $\frac{d\tilde{\ell}(t)}{d \rvw_r(t)} = \frac{d \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i}{d \rvw_r(t)}$, $\forall t \in O\left( \frac{\sigma}{\eta n} \right)$. Let $\rmW(t+1) = \rmW(t) - \eta \cdot \frac{d \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i}{d \rmW(t)}$, by \cref{lem:parameter_smoothness},
\begin{equation*}
\begin{split}
    &\rvpi_i\left( \rmW(t+1) \right)^\top \hat{\rvtilder}_i - \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i \\
    &\le - \eta \left\| \frac{d \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i}{d \rmW(t)} \right\|_F^2 + 8 h m \eta^2 \left\| \frac{d \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i}{d \rmW(t)} \right\|_F^2 \\
    &= - \eta \sum\limits_{r=1}^{m}{ \left\| \frac{d \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i}{d \rvw_r(t)} \right\|_2^2 } \\
    &\qquad + 8 h m \eta^2 \sum\limits_{r=1}^{m}{ \left\| \frac{d \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i}{d \rvw_r(t)} \right\|_2^2 } \\
    &\le - \left( \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i \right)^2 \cdot \left[ \frac{\eta m c_t^2 \delta^2}{n^4} - 8 \eta^2 h m^2 \right] \\
    &= - \left( \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i \right)^2 \cdot \left( \frac{\eta m c_t^2 \delta^2}{2n^4} \right).
\end{split}
\end{equation*}
Divided by $\left( \rvpi_i\left( \rmW(t+1) \right)^\top \hat{\rvtilder}_i\right) \cdot \left( \rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i \right)$,
\begin{equation*}
\begin{split}
    &\frac{1}{\rvpi_i\left( \rmW(t+1) \right)^\top \hat{\rvtilder}_i} - \frac{1}{\rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i} \ge \\
    &\frac{\rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i}{\rvpi_i\left( \rmW(t+1) \right)^\top \hat{\rvtilder}_i} \cdot \left( \frac{\eta m c_t^2 \delta^2}{2n^4} \right) \ge \frac{\eta m c_t^2 \delta^2}{2n^4}.
\end{split}
\end{equation*}
Denote $c \triangleq \min\limits_{t \ge 0}{\left\{ c_t \right\}} > 0$ because $\rvpi_i\left( \rmW(t) \right)$ is a softmax policy.
Sum up the inequality from $0$ to $t$,
\begin{equation*}
\begin{split}
    \frac{1}{\rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i} \ge \frac{\eta m c^2 \delta^2}{2n^4} \cdot t.
\end{split}
\end{equation*}
Therefore, after $t =  \frac{2n^4}{\eta m c^2 \delta^2 \varepsilon}$ policy gradient updates, $\rvpi_i\left( \rmW(t) \right)^\top \hat{\rvtilder}_i \le \varepsilon$. And the $t$th policy gradient update in the play-learning phase corresponds to $t + T^{\frac{2}{3} + \beta}$ in \cref{alg:policy_gradient_uniform_exploration}. Finally, make sure that all the update iterations terminate within $\frac{\tau}{\eta}$, i.e.,
Let $\frac{2n^4}{\eta m c^2 \delta^2 \varepsilon} \le \frac{\sigma}{n \eta} = \frac{1}{n \eta \sqrt{m}}$, we obtain the results.
\end{proof}


\end{document}
